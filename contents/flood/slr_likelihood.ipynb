{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choosing A Likelihood Function {#sec-slr-likelihood}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| echo: false\n",
    "\n",
    "import Pkg\n",
    "Pkg.activate(\".\"; io=devnull);\n",
    "Pkg.instantiate(; io=devnull);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Calibration\n",
    "\n",
    "Now that we have selected a sea-level rise (SLR) model, the next step in our analysis is to select parameter values. This procedure is called *model calibration*. In @sec-slr-model, we found values which minimized the root-mean-square error. This yielded individual parameter values, or *point estimates*, and so is an example of a deterministic approach to calibration. However, there are potential downsides to relying on point estimates. Most importantly, the use of point estimates results in a deterministic model output, with no representation of uncertainties. This is problematic, at one consequence is that we would end up with a single projection value of the global mean sea-level resulting from a given temperature trajectory. But we know that our model is very simplified, and does not perfectly match the data --- why would we trust it to give us perfect values for the future? \n",
    "\n",
    "::: {.column-margin}\n",
    "In general, we should be suspicious (and at the least, highly skeptical) if a given model fits data *too* perfectly. This is because there are all sorts of sources of \"error\", including observation/data-reconstruction errors and model simplifications. As the famous statistician George Box wrote, \"all models are wrong, but some are useful\" [@boxRobustnessStrategyScientific1979]: the critical question is whether a model gives us insights into key dynamics.\n",
    ":::\n",
    "\n",
    "Instead of putting too much faith in our simple model, we can instead view it as an *approximation*, which will give us insights into the approximate relationship between global mean temperature change and sea-level rise. However, we are still confronted with the problem of relying too much on point estimates of the model parameters. While our previous optimization minimized the least-squares, there could be many different values which have a similar level of error.\n",
    "\n",
    "Our goal, then, is to quantify uncertainties relevant to future projections of sea levels. This will allow us to obtain a probabilistic representation of the contribution of SLR to future flood risk. Notice that our model,\n",
    "$$\\Delta H(t) = \\alpha \\left(T(t) - T_\\text{eq}\\right),$$\n",
    "is deterministic. @fig-slr-model-fits shows us that the best-fit model (using RMSE as the metric for deviation), did not perfectly fit the data, which is typically the case.\n",
    "\n",
    "The difference between the data $y_t$ and the model output $\\hat{y}_t$ at each time $t$ is called the *residual* or the *discrepancy*, which we can denote as $\\omega_t$. That is,\n",
    "$$\\omega_t = y_t - \\hat{y}_t.$$ \n",
    "As the contributions to the discrepancy $\\omega_t$ are uncertain, we can construct a statistical model for it. As the data can be viewed as being fixed for any given calibration exercise, This is an important choice, as this statistical model has an effect on the associated model parameter distributions [@brynjarsdottirLearningPhysicalParameters2014]. \n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.7.3",
   "language": "julia",
   "name": "julia-1.7"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.7.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
